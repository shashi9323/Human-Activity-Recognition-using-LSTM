{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"},"colab":{"name":"Copy of HAR_LSTM.ipynb","version":"0.3.2","provenance":[{"file_id":"14BHq7O_RvrfpfqkA7z_yD3tvi8Fd4ZJS","timestamp":1568481810797}],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xXz1BrTJP-mS","colab_type":"code","outputId":"05266355-c1d5-452f-d202-4ba849e524b1","executionInfo":{"status":"ok","timestamp":1568521822349,"user_tz":-330,"elapsed":59167,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7665iTX6P-mX","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GfuPqqrmP-ma","colab_type":"code","colab":{}},"source":["# Activities are the class labels\n","# It is a 6 class classification\n","ACTIVITIES = {\n","    0: 'WALKING',\n","    1: 'WALKING_UPSTAIRS',\n","    2: 'WALKING_DOWNSTAIRS',\n","    3: 'SITTING',\n","    4: 'STANDING',\n","    5: 'LAYING',\n","}\n","\n","# Utility function to print the confusion matrix\n","def confusion_matrix(Y_true, Y_pred):\n","    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n","    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n","\n","    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S3VaT51FP-me","colab_type":"text"},"source":["### Data"]},{"cell_type":"code","metadata":{"id":"ug6Ysq2iP-mg","colab_type":"code","colab":{}},"source":["# Data directory\n","DATADIR = 'UCI_HAR_Dataset'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yec759X0P-mj","colab_type":"code","colab":{}},"source":["# Raw data signals\n","# Signals are from Accelerometer and Gyroscope\n","# The signals are in x,y,z directions\n","# Sensor signals are filtered to have only body acceleration\n","# excluding the acceleration due to gravity\n","# Triaxial acceleration from the accelerometer is total acceleration\n","SIGNALS = [\n","    \"body_acc_x\",\n","    \"body_acc_y\",\n","    \"body_acc_z\",\n","    \"body_gyro_x\",\n","    \"body_gyro_y\",\n","    \"body_gyro_z\",\n","    \"total_acc_x\",\n","    \"total_acc_y\",\n","    \"total_acc_z\"\n","]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OjiYApZgP-mn","colab_type":"code","colab":{}},"source":["# Utility function to read the data from csv file\n","def _read_csv(filename):\n","    return pd.read_csv(filename, delim_whitespace=True, header=None)\n","\n","# Utility function to load the load\n","def load_signals(subset):\n","    signals_data = []\n","\n","    for signal in SIGNALS:\n","        filename = f'/content/drive/My Drive/Colab Notebooks/HumanActivityRecognition.zip (Unzipped Files)/HAR/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n","        signals_data.append(\n","            _read_csv(filename).as_matrix()\n","        ) \n","\n","    # Transpose is used to change the dimensionality of the output,\n","    # aggregating the signals by combination of sample/timestep.\n","    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n","    return np.transpose(signals_data, (1, 2, 0))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vis4YCtzP-mr","colab_type":"code","colab":{}},"source":["\n","def load_y(subset):\n","    \"\"\"\n","    The objective that we are trying to predict is a integer, from 1 to 6,\n","    that represents a human activity. We return a binary representation of \n","    every sample objective as a 6 bits vector using One Hot Encoding\n","    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n","    \"\"\"\n","    filename = f'/content/drive/My Drive/Colab Notebooks/HumanActivityRecognition.zip (Unzipped Files)/HAR/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n","    y = _read_csv(filename)[0]\n","\n","    return pd.get_dummies(y).as_matrix()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kw41x4fLP-mu","colab_type":"code","colab":{}},"source":["def load_data():\n","    \"\"\"\n","    Obtain the dataset from multiple files.\n","    Returns: X_train, X_test, y_train, y_test\n","    \"\"\"\n","    X_train, X_test = load_signals('train'), load_signals('test')\n","    y_train, y_test = load_y('train'), load_y('test')\n","\n","    return X_train, X_test, y_train, y_test"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CSv5xasaP-mz","colab_type":"code","colab":{}},"source":["# Importing tensorflow\n","np.random.seed(42)\n","import tensorflow as tf\n","tf.set_random_seed(42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eZc4RTvgP-m4","colab_type":"code","colab":{}},"source":["# Configuring a session\n","session_conf = tf.ConfigProto(\n","    intra_op_parallelism_threads=1,\n","    inter_op_parallelism_threads=1\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1AugXfHQP-m7","colab_type":"code","outputId":"bc586057-a338-41ee-9bca-f90117c4fe73","executionInfo":{"status":"ok","timestamp":1568521824678,"user_tz":-330,"elapsed":61314,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Import Keras\n","from keras import backend as K\n","sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n","K.set_session(sess)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"FpG3VL6yP-nB","colab_type":"code","colab":{}},"source":["# Importing libraries\n","from keras.models import Sequential\n","from keras.layers import LSTM\n","from keras.layers.core import Dense, Dropout"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MK0IdA-3P-nF","colab_type":"code","colab":{}},"source":["# Initializing parameters\n","epochs = 30\n","batch_size = 16\n","n_hidden = 32"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pRFSqDwRP-nJ","colab_type":"code","colab":{}},"source":["# Utility function to count the number of classes\n","def _count_classes(y):\n","    return len(set([tuple(category) for category in y]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AehkmZvXP-nO","colab_type":"code","outputId":"d5b5b26c-34a0-4d40-a104-e6376146dbb2","executionInfo":{"status":"ok","timestamp":1568521845389,"user_tz":-330,"elapsed":81979,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# Loading the train and test data\n","X_train, X_test, Y_train, Y_test = load_data()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n","  if sys.path[0] == '':\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"5p1SeWuzP-nS","colab_type":"code","outputId":"c6b46c9b-79d5-479a-c28a-56755fb5552e","executionInfo":{"status":"ok","timestamp":1568521845390,"user_tz":-330,"elapsed":81967,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["timesteps = 128\n","input_dim = len(X_train[0][0])\n","n_classes = _count_classes(Y_train)\n","input_shape = (timesteps, input_dim)\n","\n","print(timesteps)\n","print(input_dim)\n","print(len(X_train))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["128\n","9\n","7352\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qDmh8BxQU-wu","colab_type":"text"},"source":["**LSTM Model 2**"]},{"cell_type":"markdown","metadata":{"id":"pBpIhqKIP3ub","colab_type":"text"},"source":["We tried several different models with varying number of layers an different dropout rates. The best accuracy we achived is 93.8% with thebelow model."]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"cb6ce097-c61b-4d21-f063-bfe68c85eeda","executionInfo":{"status":"ok","timestamp":1567252961831,"user_tz":-330,"elapsed":2124,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}},"id":"9TIrioMrW-56","colab":{"base_uri":"https://localhost:8080/","height":615}},"source":["from keras.layers import BatchNormalization\n","# Initiliazing the sequential model\n","model2 = Sequential()\n","# Configuring the parameters\n","model2.add(LSTM(128, return_sequences=True, input_shape=(timesteps, input_dim), kernel_initializer='glorot_normal'))\n","# Adding a dropout layer\n","model2.add(Dropout(0.2))\n","model2.add(BatchNormalization())\n","model2.add(LSTM(64))\n","# Adding a dropout layer\n","model2.add(Dropout(0.5))\n","# Adding a dense output layer with sigmoid activation\n","model2.add(Dense(n_classes, activation='sigmoid'))\n","model2.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0831 12:02:43.248532 139997190457216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0831 12:02:43.254620 139997190457216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0831 12:02:43.269654 139997190457216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n","\n","W0831 12:02:43.571439 139997190457216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","W0831 12:02:43.581346 139997190457216 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0831 12:02:43.792232 139997190457216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_1 (LSTM)                (None, 128, 128)          70656     \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 128, 128)          0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 128, 128)          512       \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 64)                49408     \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 6)                 390       \n","=================================================================\n","Total params: 120,966\n","Trainable params: 120,710\n","Non-trainable params: 256\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qpMW12xnW-6D","colab":{}},"source":["# Compiling the model\n","model2.compile(loss='categorical_crossentropy\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","\n","from keras.callbacks import ModelCheckpoint\n","\n","filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [checkpoint]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"dbce59a2-cbb9-4eee-844e-4cc92ef6c6d0","executionInfo":{"status":"ok","timestamp":1567260447155,"user_tz":-330,"elapsed":7054711,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}},"id":"G1yUrMw4W-6H","colab":{"base_uri":"https://localhost:8080/","height":2091}},"source":["# Training the model\n","model2.fit(X_train, Y_train, batch_size=batch_size, validation_data=(X_test, Y_test), epochs=epochs, callbacks=callbacks_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 7352 samples, validate on 2947 samples\n","Epoch 1/30\n","7352/7352 [==============================] - 236s 32ms/step - loss: 0.2719 - acc: 0.9102 - val_loss: 0.2652 - val_acc: 0.9060\n","\n","Epoch 00001: val_acc improved from -inf to 0.90601, saving model to weights-improvement-01-0.91.hdf5\n","Epoch 2/30\n","7352/7352 [==============================] - 235s 32ms/step - loss: 0.1989 - acc: 0.9304 - val_loss: 0.2596 - val_acc: 0.8972\n","\n","Epoch 00002: val_acc did not improve from 0.90601\n","Epoch 3/30\n","7352/7352 [==============================] - 234s 32ms/step - loss: 0.1877 - acc: 0.9289 - val_loss: 0.1934 - val_acc: 0.9169\n","\n","Epoch 00003: val_acc improved from 0.90601 to 0.91686, saving model to weights-improvement-03-0.92.hdf5\n","Epoch 4/30\n","7352/7352 [==============================] - 236s 32ms/step - loss: 0.1766 - acc: 0.9331 - val_loss: 0.1692 - val_acc: 0.9318\n","\n","Epoch 00004: val_acc improved from 0.91686 to 0.93180, saving model to weights-improvement-04-0.93.hdf5\n","Epoch 5/30\n","7352/7352 [==============================] - 236s 32ms/step - loss: 0.1649 - acc: 0.9370 - val_loss: 0.2129 - val_acc: 0.9267\n","\n","Epoch 00005: val_acc did not improve from 0.93180\n","Epoch 6/30\n","7352/7352 [==============================] - 236s 32ms/step - loss: 0.1554 - acc: 0.9423 - val_loss: 0.2954 - val_acc: 0.9175\n","\n","Epoch 00006: val_acc did not improve from 0.93180\n","Epoch 7/30\n","7352/7352 [==============================] - 235s 32ms/step - loss: 0.1607 - acc: 0.9421 - val_loss: 0.2073 - val_acc: 0.9277\n","\n","Epoch 00007: val_acc did not improve from 0.93180\n","Epoch 8/30\n","7352/7352 [==============================] - 235s 32ms/step - loss: 0.1418 - acc: 0.9438 - val_loss: 0.2673 - val_acc: 0.9192\n","\n","Epoch 00008: val_acc did not improve from 0.93180\n","Epoch 9/30\n","7352/7352 [==============================] - 235s 32ms/step - loss: 0.1521 - acc: 0.9414 - val_loss: 0.1969 - val_acc: 0.9284\n","\n","Epoch 00009: val_acc did not improve from 0.93180\n","Epoch 10/30\n","7352/7352 [==============================] - 236s 32ms/step - loss: 0.1413 - acc: 0.9445 - val_loss: 0.3203 - val_acc: 0.9216\n","\n","Epoch 00010: val_acc did not improve from 0.93180\n","Epoch 11/30\n","7352/7352 [==============================] - 233s 32ms/step - loss: 0.1506 - acc: 0.9448 - val_loss: 0.2370 - val_acc: 0.9240\n","\n","Epoch 00011: val_acc did not improve from 0.93180\n","Epoch 12/30\n","7352/7352 [==============================] - 234s 32ms/step - loss: 0.1403 - acc: 0.9497 - val_loss: 0.4236 - val_acc: 0.8979\n","\n","Epoch 00012: val_acc did not improve from 0.93180\n","Epoch 13/30\n","7352/7352 [==============================] - 235s 32ms/step - loss: 0.1420 - acc: 0.9453 - val_loss: 0.4034 - val_acc: 0.9189\n","\n","Epoch 00013: val_acc did not improve from 0.93180\n","Epoch 14/30\n","7352/7352 [==============================] - 235s 32ms/step - loss: 0.1321 - acc: 0.9484 - val_loss: 0.4115 - val_acc: 0.9220\n","\n","Epoch 00014: val_acc did not improve from 0.93180\n","Epoch 15/30\n","7352/7352 [==============================] - 234s 32ms/step - loss: 0.1340 - acc: 0.9495 - val_loss: 0.2219 - val_acc: 0.9311\n","\n","Epoch 00015: val_acc did not improve from 0.93180\n","Epoch 16/30\n","7352/7352 [==============================] - 234s 32ms/step - loss: 0.1408 - acc: 0.9498 - val_loss: 0.1865 - val_acc: 0.9386\n","\n","Epoch 00016: val_acc improved from 0.93180 to 0.93858, saving model to weights-improvement-16-0.94.hdf5\n","Epoch 17/30\n","7352/7352 [==============================] - 235s 32ms/step - loss: 0.1361 - acc: 0.9497 - val_loss: 0.2780 - val_acc: 0.9284\n","\n","Epoch 00017: val_acc did not improve from 0.93858\n","Epoch 18/30\n","7352/7352 [==============================] - 235s 32ms/step - loss: 0.1449 - acc: 0.9475 - val_loss: 0.3059 - val_acc: 0.9260\n","\n","Epoch 00018: val_acc did not improve from 0.93858\n","Epoch 19/30\n","7352/7352 [==============================] - 233s 32ms/step - loss: 0.1303 - acc: 0.9509 - val_loss: 0.3003 - val_acc: 0.9240\n","\n","Epoch 00019: val_acc did not improve from 0.93858\n","Epoch 20/30\n","7352/7352 [==============================] - 235s 32ms/step - loss: 0.1431 - acc: 0.9486 - val_loss: 0.4032 - val_acc: 0.9152\n","\n","Epoch 00020: val_acc did not improve from 0.93858\n","Epoch 21/30\n","7352/7352 [==============================] - 235s 32ms/step - loss: 0.1536 - acc: 0.9467 - val_loss: 0.4324 - val_acc: 0.9165\n","\n","Epoch 00021: val_acc did not improve from 0.93858\n","Epoch 22/30\n","7352/7352 [==============================] - 234s 32ms/step - loss: 0.1359 - acc: 0.9471 - val_loss: 0.4118 - val_acc: 0.9155\n","\n","Epoch 00022: val_acc did not improve from 0.93858\n","Epoch 23/30\n","7352/7352 [==============================] - 234s 32ms/step - loss: 0.1328 - acc: 0.9509 - val_loss: 0.3244 - val_acc: 0.9247\n","\n","Epoch 00023: val_acc did not improve from 0.93858\n","Epoch 24/30\n","7352/7352 [==============================] - 236s 32ms/step - loss: 0.1315 - acc: 0.9491 - val_loss: 0.4381 - val_acc: 0.9179\n","\n","Epoch 00024: val_acc did not improve from 0.93858\n","Epoch 25/30\n","7352/7352 [==============================] - 236s 32ms/step - loss: 0.1373 - acc: 0.9445 - val_loss: 0.2475 - val_acc: 0.9321\n","\n","Epoch 00025: val_acc did not improve from 0.93858\n","Epoch 26/30\n","7352/7352 [==============================] - 236s 32ms/step - loss: 0.6463 - acc: 0.7078 - val_loss: 1.7912 - val_acc: 0.1683\n","\n","Epoch 00026: val_acc did not improve from 0.93858\n","Epoch 27/30\n","7352/7352 [==============================] - 235s 32ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n","\n","Epoch 00027: val_acc did not improve from 0.93858\n","Epoch 28/30\n","7352/7352 [==============================] - 235s 32ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n","\n","Epoch 00028: val_acc did not improve from 0.93858\n","Epoch 29/30\n","7352/7352 [==============================] - 235s 32ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n","\n","Epoch 00029: val_acc did not improve from 0.93858\n","Epoch 30/30\n","7352/7352 [==============================] - 235s 32ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n","\n","Epoch 00030: val_acc did not improve from 0.93858\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f52f9bde7f0>"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"Hmq37J1l2bkS","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zH93Reu0W-6M","outputId":"cfc6df5c-d235-41c9-9a49-27a84998b584","executionInfo":{"status":"ok","timestamp":1567260463557,"user_tz":-330,"elapsed":3429792,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["## Confusion Matrix\n","print(confusion_matrix(Y_test, model2.predict(X_test)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Pred                STANDING  WALKING\n","True                                 \n","LAYING                     0      537\n","SITTING                    0      491\n","STANDING                   0      532\n","WALKING                    0      496\n","WALKING_DOWNSTAIRS         0      420\n","WALKING_UPSTAIRS           1      470\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iHGode0SW-6R","outputId":"3fb565c4-35ff-4a92-991d-02853b68939a","executionInfo":{"status":"ok","timestamp":1567260479866,"user_tz":-330,"elapsed":3445678,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["score = model2.evaluate(X_test, Y_test)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2947/2947 [==============================] - 17s 6ms/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","cellView":"both","id":"bRa0WgjsW-6V","outputId":"dacc80e3-f6c3-4f02-989a-20b26ee56ec6","executionInfo":{"status":"ok","timestamp":1567260479867,"user_tz":-330,"elapsed":3445410,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["score\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1.7911514966496784, 0.168306752629793]"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"082ab7f3-20f6-4348-88ac-9847a68b6b0a","executionInfo":{"status":"ok","timestamp":1567261721611,"user_tz":-330,"elapsed":1671,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}},"id":"_wLF0mG6Epfc","colab":{"base_uri":"https://localhost:8080/","height":357}},"source":["from keras.layers import BatchNormalization\n","# Initiliazing the sequential model\n","model2 = Sequential()\n","# Configuring the parameters\n","model2.add(LSTM(128, return_sequences=True, input_shape=(timesteps, input_dim), kernel_initializer='glorot_normal'))\n","# Adding a dropout layer\n","model2.add(Dropout(0.2))\n","model2.add(BatchNormalization())\n","model2.add(LSTM(64))\n","# Adding a dropout layer\n","model2.add(Dropout(0.5))\n","# Adding a dense output layer with sigmoid activation\n","model2.add(Dense(n_classes, activation='sigmoid'))\n","model2.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_3 (LSTM)                (None, 128, 128)          70656     \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 128, 128)          0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 128, 128)          512       \n","_________________________________________________________________\n","lstm_4 (LSTM)                (None, 64)                49408     \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 6)                 390       \n","=================================================================\n","Total params: 120,966\n","Trainable params: 120,710\n","Non-trainable params: 256\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FisGVKwHEpfh","colab":{}},"source":["# Compiling the model\n","model2.load_weights(\"/content/weights-improvement-16-0.94.hdf5\")\n","model2.compile(loss='categorical_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","\n","from keras.callbacks import ModelCheckpoint\n","\n","filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [checkpoint]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"b3581e45-d227-4936-a330-3b4330af9fba","executionInfo":{"status":"ok","timestamp":1567266123012,"user_tz":-330,"elapsed":18326,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}},"id":"BiX4punpEpfj","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["scores = model2.evaluate(X_test, Y_test)\n","print(\"%s: %.2f%%\" % (model2.metrics_names[1], scores[1]*100))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2947/2947 [==============================] - 18s 6ms/step\n","acc: 93.86%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8peeagQtEpfn"},"source":[""]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"96e9c2e8-a175-4dc4-9366-dd90b96dc12d","executionInfo":{"status":"ok","timestamp":1567266146800,"user_tz":-330,"elapsed":17071,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}},"id":"pbxZXbVfEpfo","colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["## Confusion Matrix\n","print(confusion_matrix(Y_test, model2.predict(X_test)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n","True                                 ...                                      \n","LAYING                 537        0  ...                   0                 0\n","SITTING                  0      372  ...                   0                 1\n","STANDING                 0       46  ...                   0                 0\n","WALKING                  0        0  ...                   2                 0\n","WALKING_DOWNSTAIRS       0        0  ...                 420                 0\n","WALKING_UPSTAIRS         0        0  ...                   3               459\n","\n","[6 rows x 6 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"l5MsvgHhjhtt","colab_type":"text"},"source":["**Conclusions**"]},{"cell_type":"code","metadata":{"id":"V-fPs-Ggikvv","colab_type":"code","outputId":"8fb97b43-7574-44e1-c851-034e3d69eeb0","executionInfo":{"status":"ok","timestamp":1567344984274,"user_tz":-330,"elapsed":1305,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["from prettytable import PrettyTable\n","    \n","x = PrettyTable()\n","\n","x.field_names = [\"Model Name\",\"Number of LSTM Layers\", \"Dropout Implemented\", \"Batch Normalization implemented\",\"Epochs Run\",\"Initializer used\",\"Optimizer\", \"Accuracy Achieved\"]\n","\n","x.add_row([\"Model 1\", 1, 0.5,\"No\", 30,\"none\",\"Sigmoid\", 0.908 ])\n","x.add_row([\"Model with Zero Initializer\", 1, 0.5,\"NO\",\"Zero\", \"Sigmoid\", 30,0.892 ])\n","x.add_row([\"Model with Glorot Normal Initializer\", 1, 0.5,\"NO\",\"Glorot Normal\", \"Sigmoid\", 30,0.91 ])\n","x.add_row([\"LSTM Model 1\", 2, \"Yes\" ,\"NO\",\"Glorot Normal\", \"Sigmoid\", 30,0.896 ])\n","x.add_row([\"LSTM Model 2\", 2, \"Yes\" ,\"Yes\",\"Glorot Normal\", \"Sigmoid\", 25 ,0.938 ])\n","x.add_row([\"LSTM Model with RELU with Batch Normaliztion\", 2, \"Yes\" ,\"YES\",\"Glorot Normal\", \"RELU\", 30,0.921 ])\n","\n","print(x)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+----------------------------------------------+-----------------------+---------------------+---------------------------------+---------------+------------------+-----------+-------------------+\n","|                  Model Name                  | Number of LSTM Layers | Dropout Implemented | Batch Normalization implemented |   Epochs Run  | Initializer used | Optimizer | Accuracy Achieved |\n","+----------------------------------------------+-----------------------+---------------------+---------------------------------+---------------+------------------+-----------+-------------------+\n","|                   Model 1                    |           1           |         0.5         |                No               |       30      |       none       |  Sigmoid  |       0.908       |\n","|         Model with Zero Initializer          |           1           |         0.5         |                NO               |      Zero     |     Sigmoid      |     30    |       0.892       |\n","|     Model with Glorot Normal Initializer     |           1           |         0.5         |                NO               | Glorot Normal |     Sigmoid      |     30    |        0.91       |\n","|                 LSTM Model 1                 |           2           |         Yes         |                NO               | Glorot Normal |     Sigmoid      |     30    |       0.896       |\n","|                 LSTM Model 2                 |           2           |         Yes         |               Yes               | Glorot Normal |     Sigmoid      |     25    |       0.938       |\n","| LSTM Model with RELU with Batch Normaliztion |           2           |         Yes         |               YES               | Glorot Normal |       RELU       |     30    |       0.921       |\n","+----------------------------------------------+-----------------------+---------------------+---------------------------------+---------------+------------------+-----------+-------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yPcIyJBsAVD8","colab_type":"text"},"source":["1) Initially tried using GridsearchCV to optimize parameters but since it was taking too long, we tried different parameters.\n","2) We used different combinations of umber of hidden layers, optimizers etc.\n","3) LSTM model 2 performed the best for us which uses batch normalization with sigmoid optimizer. We got an accuracy of 93.8 on 25 epochs after which it was overfitting."]},{"cell_type":"markdown","metadata":{"id":"l6sH0Mdizeam","colab_type":"text"},"source":["**Updated Assignment**"]},{"cell_type":"code","metadata":{"id":"JQyxhDyy3Sls","colab_type":"code","colab":{}},"source":["from __future__ import print_function\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Reshape, Softmax\n","from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, TimeDistributed\n","from keras import backend as K"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JU5JWtiWzg7I","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":258},"outputId":"9b9279e4-8933-4396-eaf1-ef51a65284a2","executionInfo":{"status":"ok","timestamp":1568522098520,"user_tz":-330,"elapsed":1708,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}}},"source":["from keras.layers import BatchNormalization\n","# Initiliazing the sequential model\n","model1 = Sequential()\n","# Configuring the parameters\n","model1.add(LSTM(128, return_sequences=True, input_shape=(timesteps, input_dim), kernel_initializer='he_uniform'))\n","# Adding a dropout layer\n","model1.add(Dropout(0.2))\n","model1.add(LSTM(64, return_sequences=True))\n","model1.add(Conv1D(32, kernel_size=(3), activation='relu'))\n","model1.add(Dropout(0.5))\n","model1.add(Conv1D(64, kernel_size=(3) , activation='relu'))\n","model1.add(MaxPooling1D(pool_size=2))\n","model1.add(Flatten())\n","model1.add(Dense(50, activation='relu'))\n","\n","model1.add(Dense(6, activation='softmax'))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YHlrQJfQ7QE1","colab_type":"code","colab":{}},"source":["model1.compile(loss='categorical_crossentropy',\n","              optimizer='Adam',\n","              metrics=['accuracy'])\n","\n","from keras.callbacks import ModelCheckpoint\n","\n","filepath=\"/content/drive/My Drive/Colab Notebooks/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [checkpoint]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dejV-p6T7s4C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":2145},"outputId":"3a944e28-18f4-4ae0-d5c6-faaab7502819","executionInfo":{"status":"ok","timestamp":1568493154935,"user_tz":-330,"elapsed":6912525,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}}},"source":["\n","history=model1.fit(X_train, Y_train, batch_size=batch_size, validation_data=(X_test, Y_test), epochs=epochs, callbacks=callbacks_list, verbose=1)"],"execution_count":89,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Train on 7352 samples, validate on 2947 samples\n","Epoch 1/30\n","7352/7352 [==============================] - 246s 33ms/step - loss: 0.3965 - acc: 0.8366 - val_loss: 0.3445 - val_acc: 0.8700\n","\n","Epoch 00001: val_acc improved from -inf to 0.87004, saving model to /content/drive/My Drive/Colab Notebooks/weights-improvement-01-0.87.hdf5\n","Epoch 2/30\n","7352/7352 [==============================] - 230s 31ms/step - loss: 0.1508 - acc: 0.9392 - val_loss: 0.4574 - val_acc: 0.8938\n","\n","Epoch 00002: val_acc improved from 0.87004 to 0.89379, saving model to /content/drive/My Drive/Colab Notebooks/weights-improvement-02-0.89.hdf5\n","Epoch 3/30\n","7352/7352 [==============================] - 228s 31ms/step - loss: 0.1408 - acc: 0.9445 - val_loss: 0.3957 - val_acc: 0.8897\n","\n","Epoch 00003: val_acc did not improve from 0.89379\n","Epoch 4/30\n","7352/7352 [==============================] - 228s 31ms/step - loss: 0.1148 - acc: 0.9483 - val_loss: 0.3776 - val_acc: 0.9080\n","\n","Epoch 00004: val_acc improved from 0.89379 to 0.90804, saving model to /content/drive/My Drive/Colab Notebooks/weights-improvement-04-0.91.hdf5\n","Epoch 5/30\n","7352/7352 [==============================] - 229s 31ms/step - loss: 0.1259 - acc: 0.9487 - val_loss: 0.4009 - val_acc: 0.9135\n","\n","Epoch 00005: val_acc improved from 0.90804 to 0.91347, saving model to /content/drive/My Drive/Colab Notebooks/weights-improvement-05-0.91.hdf5\n","Epoch 6/30\n","7352/7352 [==============================] - 228s 31ms/step - loss: 0.2286 - acc: 0.9407 - val_loss: 0.4281 - val_acc: 0.8945\n","\n","Epoch 00006: val_acc did not improve from 0.91347\n","Epoch 7/30\n","7352/7352 [==============================] - 230s 31ms/step - loss: 0.1395 - acc: 0.9502 - val_loss: 0.4396 - val_acc: 0.8833\n","\n","Epoch 00007: val_acc did not improve from 0.91347\n","Epoch 8/30\n","7352/7352 [==============================] - 233s 32ms/step - loss: 0.1409 - acc: 0.9505 - val_loss: 0.4458 - val_acc: 0.9019\n","\n","Epoch 00008: val_acc did not improve from 0.91347\n","Epoch 9/30\n","7352/7352 [==============================] - 232s 32ms/step - loss: 0.1553 - acc: 0.9483 - val_loss: 0.3261 - val_acc: 0.9016\n","\n","Epoch 00009: val_acc did not improve from 0.91347\n","Epoch 10/30\n","7352/7352 [==============================] - 233s 32ms/step - loss: 0.1378 - acc: 0.9508 - val_loss: 0.3983 - val_acc: 0.9030\n","\n","Epoch 00010: val_acc did not improve from 0.91347\n","Epoch 11/30\n","7352/7352 [==============================] - 231s 31ms/step - loss: 0.1348 - acc: 0.9539 - val_loss: 0.3865 - val_acc: 0.9084\n","\n","Epoch 00011: val_acc did not improve from 0.91347\n","Epoch 12/30\n","7352/7352 [==============================] - 233s 32ms/step - loss: 0.1645 - acc: 0.9448 - val_loss: 0.2230 - val_acc: 0.9128\n","\n","Epoch 00012: val_acc did not improve from 0.91347\n","Epoch 13/30\n","7352/7352 [==============================] - 232s 31ms/step - loss: 0.1083 - acc: 0.9529 - val_loss: 0.2280 - val_acc: 0.9270\n","\n","Epoch 00013: val_acc improved from 0.91347 to 0.92704, saving model to /content/drive/My Drive/Colab Notebooks/weights-improvement-13-0.93.hdf5\n","Epoch 14/30\n","7352/7352 [==============================] - 232s 32ms/step - loss: 0.0945 - acc: 0.9576 - val_loss: 0.1835 - val_acc: 0.9382\n","\n","Epoch 00014: val_acc improved from 0.92704 to 0.93824, saving model to /content/drive/My Drive/Colab Notebooks/weights-improvement-14-0.94.hdf5\n","Epoch 15/30\n","7352/7352 [==============================] - 229s 31ms/step - loss: 0.0917 - acc: 0.9606 - val_loss: 0.2380 - val_acc: 0.9158\n","\n","Epoch 00015: val_acc did not improve from 0.93824\n","Epoch 16/30\n","7352/7352 [==============================] - 230s 31ms/step - loss: 0.1117 - acc: 0.9533 - val_loss: 0.3765 - val_acc: 0.9040\n","\n","Epoch 00016: val_acc did not improve from 0.93824\n","Epoch 17/30\n","7352/7352 [==============================] - 233s 32ms/step - loss: 0.0970 - acc: 0.9593 - val_loss: 0.2560 - val_acc: 0.9118\n","\n","Epoch 00017: val_acc did not improve from 0.93824\n","Epoch 18/30\n","7352/7352 [==============================] - 229s 31ms/step - loss: 0.0888 - acc: 0.9587 - val_loss: 0.2774 - val_acc: 0.9189\n","\n","Epoch 00018: val_acc did not improve from 0.93824\n","Epoch 19/30\n","7352/7352 [==============================] - 232s 32ms/step - loss: 0.1136 - acc: 0.9582 - val_loss: 0.3209 - val_acc: 0.9162\n","\n","Epoch 00019: val_acc did not improve from 0.93824\n","Epoch 20/30\n","7352/7352 [==============================] - 232s 32ms/step - loss: 0.0997 - acc: 0.9593 - val_loss: 0.3291 - val_acc: 0.9118\n","\n","Epoch 00020: val_acc did not improve from 0.93824\n","Epoch 21/30\n","7352/7352 [==============================] - 232s 32ms/step - loss: 0.0842 - acc: 0.9627 - val_loss: 0.3689 - val_acc: 0.9158\n","\n","Epoch 00021: val_acc did not improve from 0.93824\n","Epoch 22/30\n","7352/7352 [==============================] - 229s 31ms/step - loss: 0.0851 - acc: 0.9608 - val_loss: 0.2353 - val_acc: 0.9338\n","\n","Epoch 00022: val_acc did not improve from 0.93824\n","Epoch 23/30\n","7352/7352 [==============================] - 232s 32ms/step - loss: 0.0822 - acc: 0.9656 - val_loss: 0.4465 - val_acc: 0.9070\n","\n","Epoch 00023: val_acc did not improve from 0.93824\n","Epoch 24/30\n","7352/7352 [==============================] - 225s 31ms/step - loss: 0.0840 - acc: 0.9607 - val_loss: 0.3819 - val_acc: 0.9128\n","\n","Epoch 00024: val_acc did not improve from 0.93824\n","Epoch 25/30\n","7352/7352 [==============================] - 226s 31ms/step - loss: 0.0802 - acc: 0.9667 - val_loss: 0.4215 - val_acc: 0.9155\n","\n","Epoch 00025: val_acc did not improve from 0.93824\n","Epoch 26/30\n","7352/7352 [==============================] - 227s 31ms/step - loss: 0.0721 - acc: 0.9653 - val_loss: 0.4427 - val_acc: 0.8802\n","\n","Epoch 00026: val_acc did not improve from 0.93824\n","Epoch 27/30\n","7352/7352 [==============================] - 225s 31ms/step - loss: 0.0902 - acc: 0.9635 - val_loss: 0.3496 - val_acc: 0.9192\n","\n","Epoch 00027: val_acc did not improve from 0.93824\n","Epoch 28/30\n","7352/7352 [==============================] - 228s 31ms/step - loss: 0.1334 - acc: 0.9592 - val_loss: 0.2411 - val_acc: 0.9203\n","\n","Epoch 00028: val_acc did not improve from 0.93824\n","Epoch 29/30\n","7352/7352 [==============================] - 226s 31ms/step - loss: 0.0865 - acc: 0.9642 - val_loss: 0.2400 - val_acc: 0.9111\n","\n","Epoch 00029: val_acc did not improve from 0.93824\n","Epoch 30/30\n","7352/7352 [==============================] - 225s 31ms/step - loss: 0.0805 - acc: 0.9646 - val_loss: 0.2559 - val_acc: 0.9226\n","\n","Epoch 00030: val_acc did not improve from 0.93824\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a-7Gx7Z5ERmB","colab_type":"code","colab":{}},"source":["score = model1.evaluate(X_test, Y_test)\n","score"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L1FW7zAJMRux","colab_type":"text"},"source":["**Lets try the best performing weights from model 1**"]},{"cell_type":"code","metadata":{"id":"yrFZv_ig3LoL","colab_type":"code","colab":{}},"source":["model1.load_weights(\"/content/drive/My Drive/Colab Notebooks/weights-improvement-14-0.94.hdf5\")\n","model1.compile(loss='categorical_crossentropy',\n","              optimizer='Adam',\n","              metrics=['accuracy'])\n","scores = model1.evaluate(X_test, Y_test, verbose=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Em4u9W1NpKb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"dfcc57f7-6390-478f-9509-881cf1052f70","executionInfo":{"status":"ok","timestamp":1568526337198,"user_tz":-330,"elapsed":1506,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}}},"source":["print(\"%s: %.2f%%\" % (model1.metrics_names[1], scores[1]*100))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["acc: 93.82%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YdvVeiAnEmys","colab_type":"text"},"source":["**Model 2**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VED-huqlEiu_","colab":{}},"source":["from keras.layers import BatchNormalization\n","# Initiliazing the sequential model\n","model2 = Sequential()\n","# Configuring the parameters\n","model2.add(LSTM(96, return_sequences=True, input_shape=(timesteps, input_dim), kernel_initializer='he_uniform'))\n","# Adding a dropout layer\n","model2.add(BatchNormalization())\n","model2.add(Dropout(0.4))\n","model2.add(LSTM(64, return_sequences=True))\n","model2.add(Conv1D(32, kernel_size=(3), activation='relu'))\n","model2.add(Dropout(0.5))\n","model2.add(Conv1D(64, kernel_size=(3) , activation='relu'))\n","model2.add(MaxPooling1D(pool_size=2))\n","model2.add(Flatten())\n","model2.add(Dense(40, activation='relu'))\n","\n","model2.add(Dense(6, activation='softmax'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9O88J0mtEekJ","colab":{}},"source":["model2.compile(loss='categorical_crossentropy',\n","              optimizer='Adam',\n","              metrics=['accuracy'])\n","\n","from keras.callbacks import ModelCheckpoint\n","\n","filepath=\"/content/drive/My Drive/Colab Notebooks/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [checkpoint]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"f3df230d-a34e-4223-89cf-42835650dc4e","id":"A9dRQCUgEekN","colab":{"base_uri":"https://localhost:8080/","height":2074},"executionInfo":{"status":"ok","timestamp":1568500170319,"user_tz":-330,"elapsed":56543,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}}},"source":["\n","history=model2.fit(X_train, Y_train, batch_size=batch_size, validation_data=(X_test, Y_test), epochs=epochs, callbacks=callbacks_list, verbose=1)"],"execution_count":92,"outputs":[{"output_type":"stream","text":["Train on 7352 samples, validate on 2947 samples\n","Epoch 1/30\n","7352/7352 [==============================] - 230s 31ms/step - loss: 0.3482 - acc: 0.8594 - val_loss: 0.3936 - val_acc: 0.8537\n","\n","Epoch 00001: val_acc improved from -inf to 0.85375, saving model to /content/drive/My Drive/Colab Notebooks/weights-improvement-01-0.85.hdf5\n","Epoch 2/30\n","7352/7352 [==============================] - 230s 31ms/step - loss: 0.1437 - acc: 0.9407 - val_loss: 0.2065 - val_acc: 0.9253\n","\n","Epoch 00002: val_acc improved from 0.85375 to 0.92535, saving model to /content/drive/My Drive/Colab Notebooks/weights-improvement-02-0.93.hdf5\n","Epoch 3/30\n","7352/7352 [==============================] - 231s 31ms/step - loss: 0.1486 - acc: 0.9404 - val_loss: 0.2495 - val_acc: 0.8975\n","\n","Epoch 00003: val_acc did not improve from 0.92535\n","Epoch 4/30\n","7352/7352 [==============================] - 235s 32ms/step - loss: 0.1208 - acc: 0.9476 - val_loss: 0.1758 - val_acc: 0.9345\n","\n","Epoch 00004: val_acc improved from 0.92535 to 0.93451, saving model to /content/drive/My Drive/Colab Notebooks/weights-improvement-04-0.93.hdf5\n","Epoch 5/30\n","7352/7352 [==============================] - 235s 32ms/step - loss: 0.1187 - acc: 0.9483 - val_loss: 0.2041 - val_acc: 0.9345\n","\n","Epoch 00005: val_acc did not improve from 0.93451\n","Epoch 6/30\n","7352/7352 [==============================] - 236s 32ms/step - loss: 0.1183 - acc: 0.9510 - val_loss: 0.2449 - val_acc: 0.9206\n","\n","Epoch 00006: val_acc did not improve from 0.93451\n","Epoch 7/30\n","7352/7352 [==============================] - 234s 32ms/step - loss: 0.1352 - acc: 0.9487 - val_loss: 0.1964 - val_acc: 0.9311\n","\n","Epoch 00007: val_acc did not improve from 0.93451\n","Epoch 8/30\n","7352/7352 [==============================] - 233s 32ms/step - loss: 0.1164 - acc: 0.9517 - val_loss: 0.2838 - val_acc: 0.9111\n","\n","Epoch 00008: val_acc did not improve from 0.93451\n","Epoch 9/30\n","7352/7352 [==============================] - 232s 32ms/step - loss: 0.1367 - acc: 0.9502 - val_loss: 0.2480 - val_acc: 0.9158\n","\n","Epoch 00009: val_acc did not improve from 0.93451\n","Epoch 10/30\n","7352/7352 [==============================] - 229s 31ms/step - loss: 0.1397 - acc: 0.9433 - val_loss: 0.4027 - val_acc: 0.8907\n","\n","Epoch 00010: val_acc did not improve from 0.93451\n","Epoch 11/30\n","7352/7352 [==============================] - 230s 31ms/step - loss: 0.1145 - acc: 0.9521 - val_loss: 0.3267 - val_acc: 0.9057\n","\n","Epoch 00011: val_acc did not improve from 0.93451\n","Epoch 12/30\n","7352/7352 [==============================] - 228s 31ms/step - loss: 0.1031 - acc: 0.9542 - val_loss: 0.4357 - val_acc: 0.8873\n","\n","Epoch 00012: val_acc did not improve from 0.93451\n","Epoch 13/30\n","7352/7352 [==============================] - 231s 31ms/step - loss: 0.1047 - acc: 0.9550 - val_loss: 0.2156 - val_acc: 0.9148\n","\n","Epoch 00013: val_acc did not improve from 0.93451\n","Epoch 14/30\n","7352/7352 [==============================] - 232s 32ms/step - loss: 0.0987 - acc: 0.9535 - val_loss: 0.2443 - val_acc: 0.9240\n","\n","Epoch 00014: val_acc did not improve from 0.93451\n","Epoch 15/30\n","7352/7352 [==============================] - 231s 31ms/step - loss: 0.1056 - acc: 0.9567 - val_loss: 0.2347 - val_acc: 0.9243\n","\n","Epoch 00015: val_acc did not improve from 0.93451\n","Epoch 16/30\n","7352/7352 [==============================] - 235s 32ms/step - loss: 0.1284 - acc: 0.9517 - val_loss: 0.2049 - val_acc: 0.9332\n","\n","Epoch 00016: val_acc did not improve from 0.93451\n","Epoch 17/30\n","7352/7352 [==============================] - 232s 32ms/step - loss: 0.1044 - acc: 0.9566 - val_loss: 0.2808 - val_acc: 0.9247\n","\n","Epoch 00017: val_acc did not improve from 0.93451\n","Epoch 18/30\n","7352/7352 [==============================] - 236s 32ms/step - loss: 0.1053 - acc: 0.9558 - val_loss: 0.2362 - val_acc: 0.9298\n","\n","Epoch 00018: val_acc did not improve from 0.93451\n","Epoch 19/30\n","7352/7352 [==============================] - 232s 32ms/step - loss: 0.1469 - acc: 0.9540 - val_loss: 0.3608 - val_acc: 0.9084\n","\n","Epoch 00019: val_acc did not improve from 0.93451\n","Epoch 20/30\n","7352/7352 [==============================] - 229s 31ms/step - loss: 0.1353 - acc: 0.9584 - val_loss: 0.2695 - val_acc: 0.9281\n","\n","Epoch 00020: val_acc did not improve from 0.93451\n","Epoch 21/30\n","7352/7352 [==============================] - 227s 31ms/step - loss: 0.1229 - acc: 0.9577 - val_loss: 0.2901 - val_acc: 0.9301\n","\n","Epoch 00021: val_acc did not improve from 0.93451\n","Epoch 22/30\n","7352/7352 [==============================] - 228s 31ms/step - loss: 0.1215 - acc: 0.9588 - val_loss: 0.3133 - val_acc: 0.9243\n","\n","Epoch 00022: val_acc did not improve from 0.93451\n","Epoch 23/30\n","7352/7352 [==============================] - 232s 31ms/step - loss: 0.1275 - acc: 0.9593 - val_loss: 0.2618 - val_acc: 0.9304\n","\n","Epoch 00023: val_acc did not improve from 0.93451\n","Epoch 24/30\n","7352/7352 [==============================] - 238s 32ms/step - loss: 0.1199 - acc: 0.9607 - val_loss: 0.2991 - val_acc: 0.9172\n","\n","Epoch 00024: val_acc did not improve from 0.93451\n","Epoch 25/30\n","7352/7352 [==============================] - 242s 33ms/step - loss: 0.1441 - acc: 0.9536 - val_loss: 0.2227 - val_acc: 0.9281\n","\n","Epoch 00025: val_acc did not improve from 0.93451\n","Epoch 26/30\n","7352/7352 [==============================] - 241s 33ms/step - loss: 0.0842 - acc: 0.9627 - val_loss: 0.2441 - val_acc: 0.9291\n","\n","Epoch 00026: val_acc did not improve from 0.93451\n","Epoch 27/30\n","7352/7352 [==============================] - 237s 32ms/step - loss: 0.0936 - acc: 0.9625 - val_loss: 0.3405 - val_acc: 0.9118\n","\n","Epoch 00027: val_acc did not improve from 0.93451\n","Epoch 28/30\n","7352/7352 [==============================] - 243s 33ms/step - loss: 0.0805 - acc: 0.9652 - val_loss: 0.2926 - val_acc: 0.9169\n","\n","Epoch 00028: val_acc did not improve from 0.93451\n","Epoch 29/30\n","7352/7352 [==============================] - 238s 32ms/step - loss: 0.0715 - acc: 0.9674 - val_loss: 0.3022 - val_acc: 0.9233\n","\n","Epoch 00029: val_acc did not improve from 0.93451\n","Epoch 30/30\n","7352/7352 [==============================] - 244s 33ms/step - loss: 0.0880 - acc: 0.9633 - val_loss: 0.2915 - val_acc: 0.9264\n","\n","Epoch 00030: val_acc did not improve from 0.93451\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eaia_m2WdPds","colab_type":"text"},"source":["**Model 3**"]},{"cell_type":"code","metadata":{"id":"uKziwePAFKgS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"819bdbcd-29e3-40d5-da45-ac3db53bc3b3","executionInfo":{"status":"ok","timestamp":1568526804638,"user_tz":-330,"elapsed":2256,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}}},"source":["from keras.layers import BatchNormalization\n","# Initiliazing the sequential model\n","model3 = Sequential()\n","# Configuring the parameters\n","model3.add(LSTM(128, return_sequences=True, input_shape=(timesteps, input_dim), kernel_initializer='glorot_normal'))\n","# Adding a dropout layer\n","model3.add(Dropout(0.2))\n","model3.add(BatchNormalization())\n","model3.add(LSTM(64, return_sequences=True))\n","# Adding a dropout layer\n","model3.add(Dropout(0.5))\n","model3.add(Conv1D(32, kernel_size=(7), activation='relu'))\n","model3.add(Conv1D(24, kernel_size=(3) , activation='relu'))\n","model3.add(Dropout(0.6))\n","model3.add(MaxPooling1D(pool_size=3))\n","model3.add(Flatten())\n","model3.add(Dense(64, activation='relu'))\n","model3.add(Dense(6, activation='softmax'))\n"],"execution_count":31,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GYsANzu5ejfG","colab_type":"code","colab":{}},"source":["model3.compile(loss='categorical_crossentropy',\n","              optimizer='Adam',\n","              metrics=['accuracy'])\n","\n","from keras.callbacks import ModelCheckpoint\n","\n","filepath=\"/content/drive/My Drive/Colab Notebooks/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [checkpoint]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yq3YBSVSe8v_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":2074},"outputId":"c0145c46-c309-4a12-c751-c4e523686f5a","executionInfo":{"status":"ok","timestamp":1568534273404,"user_tz":-330,"elapsed":7435092,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}}},"source":["history=model3.fit(X_train, Y_train, batch_size=batch_size, validation_data=(X_test, Y_test), epochs=epochs, callbacks=callbacks_list, verbose=1)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Train on 7352 samples, validate on 2947 samples\n","Epoch 1/30\n","7352/7352 [==============================] - 252s 34ms/step - loss: 0.4155 - acc: 0.8377 - val_loss: 0.2822 - val_acc: 0.8948\n","\n","Epoch 00001: val_acc improved from -inf to 0.89481, saving model to /content/drive/My Drive/Colab Notebooks/weights-improvement-01-0.89.hdf5\n","Epoch 2/30\n","7352/7352 [==============================] - 248s 34ms/step - loss: 0.1709 - acc: 0.9329 - val_loss: 0.2155 - val_acc: 0.9125\n","\n","Epoch 00002: val_acc improved from 0.89481 to 0.91245, saving model to /content/drive/My Drive/Colab Notebooks/weights-improvement-02-0.91.hdf5\n","Epoch 3/30\n","7352/7352 [==============================] - 254s 35ms/step - loss: 0.1585 - acc: 0.9382 - val_loss: 0.2422 - val_acc: 0.9050\n","\n","Epoch 00003: val_acc did not improve from 0.91245\n","Epoch 4/30\n","7352/7352 [==============================] - 249s 34ms/step - loss: 0.1379 - acc: 0.9419 - val_loss: 0.2042 - val_acc: 0.9131\n","\n","Epoch 00004: val_acc improved from 0.91245 to 0.91313, saving model to /content/drive/My Drive/Colab Notebooks/weights-improvement-04-0.91.hdf5\n","Epoch 5/30\n","7352/7352 [==============================] - 241s 33ms/step - loss: 0.1633 - acc: 0.9346 - val_loss: 0.2380 - val_acc: 0.9108\n","\n","Epoch 00005: val_acc did not improve from 0.91313\n","Epoch 6/30\n","7352/7352 [==============================] - 248s 34ms/step - loss: 0.1400 - acc: 0.9446 - val_loss: 0.2342 - val_acc: 0.8948\n","\n","Epoch 00006: val_acc did not improve from 0.91313\n","Epoch 7/30\n","7352/7352 [==============================] - 251s 34ms/step - loss: 0.1418 - acc: 0.9470 - val_loss: 0.2732 - val_acc: 0.8487\n","\n","Epoch 00007: val_acc did not improve from 0.91313\n","Epoch 8/30\n","7352/7352 [==============================] - 253s 34ms/step - loss: 0.1273 - acc: 0.9456 - val_loss: 0.1879 - val_acc: 0.9267\n","\n","Epoch 00008: val_acc improved from 0.91313 to 0.92671, saving model to /content/drive/My Drive/Colab Notebooks/weights-improvement-08-0.93.hdf5\n","Epoch 9/30\n","7352/7352 [==============================] - 251s 34ms/step - loss: 0.1352 - acc: 0.9455 - val_loss: 0.2007 - val_acc: 0.9213\n","\n","Epoch 00009: val_acc did not improve from 0.92671\n","Epoch 10/30\n","7352/7352 [==============================] - 252s 34ms/step - loss: 0.1185 - acc: 0.9523 - val_loss: 0.1858 - val_acc: 0.9369\n","\n","Epoch 00010: val_acc improved from 0.92671 to 0.93688, saving model to /content/drive/My Drive/Colab Notebooks/weights-improvement-10-0.94.hdf5\n","Epoch 11/30\n","7352/7352 [==============================] - 250s 34ms/step - loss: 0.1238 - acc: 0.9479 - val_loss: 0.2415 - val_acc: 0.9213\n","\n","Epoch 00011: val_acc did not improve from 0.93688\n","Epoch 12/30\n","7352/7352 [==============================] - 251s 34ms/step - loss: 0.1475 - acc: 0.9450 - val_loss: 0.2194 - val_acc: 0.9152\n","\n","Epoch 00012: val_acc did not improve from 0.93688\n","Epoch 13/30\n","7352/7352 [==============================] - 251s 34ms/step - loss: 0.1289 - acc: 0.9468 - val_loss: 0.2314 - val_acc: 0.9206\n","\n","Epoch 00013: val_acc did not improve from 0.93688\n","Epoch 14/30\n","7352/7352 [==============================] - 251s 34ms/step - loss: 0.1370 - acc: 0.9425 - val_loss: 0.1959 - val_acc: 0.9274\n","\n","Epoch 00014: val_acc did not improve from 0.93688\n","Epoch 15/30\n","7352/7352 [==============================] - 243s 33ms/step - loss: 0.1156 - acc: 0.9532 - val_loss: 0.2208 - val_acc: 0.9376\n","\n","Epoch 00015: val_acc improved from 0.93688 to 0.93756, saving model to /content/drive/My Drive/Colab Notebooks/weights-improvement-15-0.94.hdf5\n","Epoch 16/30\n","7352/7352 [==============================] - 241s 33ms/step - loss: 0.1212 - acc: 0.9505 - val_loss: 0.2353 - val_acc: 0.9250\n","\n","Epoch 00016: val_acc did not improve from 0.93756\n","Epoch 17/30\n","7352/7352 [==============================] - 240s 33ms/step - loss: 0.1246 - acc: 0.9467 - val_loss: 0.2304 - val_acc: 0.9206\n","\n","Epoch 00017: val_acc did not improve from 0.93756\n","Epoch 18/30\n","7352/7352 [==============================] - 242s 33ms/step - loss: 0.1252 - acc: 0.9497 - val_loss: 0.1998 - val_acc: 0.9298\n","\n","Epoch 00018: val_acc did not improve from 0.93756\n","Epoch 19/30\n","7352/7352 [==============================] - 241s 33ms/step - loss: 0.1157 - acc: 0.9514 - val_loss: 0.2079 - val_acc: 0.9389\n","\n","Epoch 00019: val_acc improved from 0.93756 to 0.93892, saving model to /content/drive/My Drive/Colab Notebooks/weights-improvement-19-0.94.hdf5\n","Epoch 20/30\n","7352/7352 [==============================] - 244s 33ms/step - loss: 0.1323 - acc: 0.9487 - val_loss: 0.8692 - val_acc: 0.7058\n","\n","Epoch 00020: val_acc did not improve from 0.93892\n","Epoch 21/30\n","7352/7352 [==============================] - 242s 33ms/step - loss: 0.1366 - acc: 0.9471 - val_loss: 0.2250 - val_acc: 0.9233\n","\n","Epoch 00021: val_acc did not improve from 0.93892\n","Epoch 22/30\n","7352/7352 [==============================] - 244s 33ms/step - loss: 0.1157 - acc: 0.9520 - val_loss: 0.3511 - val_acc: 0.9196\n","\n","Epoch 00022: val_acc did not improve from 0.93892\n","Epoch 23/30\n","7352/7352 [==============================] - 244s 33ms/step - loss: 0.1230 - acc: 0.9520 - val_loss: 0.2464 - val_acc: 0.9291\n","\n","Epoch 00023: val_acc did not improve from 0.93892\n","Epoch 24/30\n","7352/7352 [==============================] - 244s 33ms/step - loss: 0.1135 - acc: 0.9538 - val_loss: 0.1736 - val_acc: 0.9427\n","\n","Epoch 00024: val_acc improved from 0.93892 to 0.94265, saving model to /content/drive/My Drive/Colab Notebooks/weights-improvement-24-0.94.hdf5\n","Epoch 25/30\n","7352/7352 [==============================] - 245s 33ms/step - loss: 0.1038 - acc: 0.9572 - val_loss: 0.1934 - val_acc: 0.9389\n","\n","Epoch 00025: val_acc did not improve from 0.94265\n","Epoch 26/30\n","7352/7352 [==============================] - 249s 34ms/step - loss: 0.1089 - acc: 0.9528 - val_loss: 0.2244 - val_acc: 0.9318\n","\n","Epoch 00026: val_acc did not improve from 0.94265\n","Epoch 27/30\n","7352/7352 [==============================] - 253s 34ms/step - loss: 0.1025 - acc: 0.9566 - val_loss: 0.2177 - val_acc: 0.9257\n","\n","Epoch 00027: val_acc did not improve from 0.94265\n","Epoch 28/30\n","7352/7352 [==============================] - 251s 34ms/step - loss: 0.1188 - acc: 0.9521 - val_loss: 0.3355 - val_acc: 0.8806\n","\n","Epoch 00028: val_acc did not improve from 0.94265\n","Epoch 29/30\n","7352/7352 [==============================] - 252s 34ms/step - loss: 0.1211 - acc: 0.9539 - val_loss: 0.2790 - val_acc: 0.9118\n","\n","Epoch 00029: val_acc did not improve from 0.94265\n","Epoch 30/30\n","7352/7352 [==============================] - 251s 34ms/step - loss: 0.1082 - acc: 0.9572 - val_loss: 0.2430 - val_acc: 0.9074\n","\n","Epoch 00030: val_acc did not improve from 0.94265\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-IuCXubt_V_H","colab_type":"text"},"source":["**BEST PERFORMANCE IN MODEL 3**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rfuxG8mH_aWn","colab":{}},"source":["model3.load_weights(\"/content/drive/My Drive/Colab Notebooks/weights-improvement-24-0.94.hdf5\")\n","model3.compile(loss='categorical_crossentropy',\n","              optimizer='Adam',\n","              metrics=['accuracy'])\n","scores = model3.evaluate(X_test, Y_test, verbose=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"8daef9cb-8e90-49cf-a874-a5074a744f80","executionInfo":{"status":"ok","timestamp":1568535375099,"user_tz":-330,"elapsed":20697,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}},"id":"od67wZ0q_aWs","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"%s: %.2f%%\" % (model3.metrics_names[1], scores[1]*100))"],"execution_count":35,"outputs":[{"output_type":"stream","text":["acc: 94.27%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uUscv7ZC_huh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"83d0b63a-e81f-4ad9-ec03-8b8d2fae39b7","executionInfo":{"status":"ok","timestamp":1568535659173,"user_tz":-330,"elapsed":1338,"user":{"displayName":"bobby m","photoUrl":"","userId":"00866644929256352068"}}},"source":["from prettytable import PrettyTable\n","    \n","x = PrettyTable()\n","\n","x.field_names = [\"Model Name\",\"Number of LSTM Layers\",\"Number of CNN Layers\", \"Dropout Implemented\", \"Batch Normalization implemented\",\"Epochs Run\",\"Initializer used\", \"Accuracy Achieved\"]\n","\n","x.add_row([\"Model 1\", 2, 3,\"Yes\", \"Yes\",30,\"He Uniform\", 0.938 ])\n","x.add_row([\"Model 2\", 2, 3,\"Yes\", \"Yes\",30,\"He Uniform\", 0.934 ])\n","x.add_row([\"Model 3\", 2, 3,\"Yes\", \"Yes\",30,\"Glorot Normal\", 0.942 ])\n","print(x)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["+------------+-----------------------+----------------------+---------------------+---------------------------------+------------+------------------+-------------------+\n","| Model Name | Number of LSTM Layers | Number of CNN Layers | Dropout Implemented | Batch Normalization implemented | Epochs Run | Initializer used | Accuracy Achieved |\n","+------------+-----------------------+----------------------+---------------------+---------------------------------+------------+------------------+-------------------+\n","|  Model 1   |           2           |          3           |         Yes         |               Yes               |     30     |    He Uniform    |       0.938       |\n","|  Model 2   |           2           |          3           |         Yes         |               Yes               |     30     |    He Uniform    |       0.934       |\n","|  Model 3   |           2           |          3           |         Yes         |               Yes               |     30     |  Glorot Normal   |       0.942       |\n","+------------+-----------------------+----------------------+---------------------+---------------------------------+------------+------------------+-------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YZE435htAtCD","colab_type":"text"},"source":["1) We used a combination of LSTM and CNN with softmax layers.\n","2) We trained 3 different models with different layer parameters, dropouts and initializers.\n","3) Model 3 performed the best by giving us an accuracy of 94.27%"]}]}